{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4a7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from stix2 import MemoryStore, parse\n",
    "# Install the stix2 library if you haven't already\n",
    "# !pip install stix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c471b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the MITRE ATT&CK Enterprise STIX JSON file saved locally\n",
    "# Replace 'path/to/enterprise-attack.json' with your file path\n",
    "MITRE_JSON_PATH = 'enterprise-attack-17.1.json' \n",
    "\n",
    "def load_mitre_stix(file_path):\n",
    "    \"\"\"Loads the STIX JSON file and creates a searchable MemoryStore.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create a MemoryStore from the STIX bundle objects\n",
    "    ms = MemoryStore(stix_data=data['objects'])\n",
    "    return ms\n",
    "\n",
    "mitre_store = load_mitre_stix(MITRE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455188d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and extracting data using raw JSON processing ---\n",
      "Found 823 ATT&CK Techniques and 1421 Mitigation Relationships.\n",
      "Raw JSON processing complete.\n",
      "\n",
      "Successfully created RAG corpus with 823 MITRE documents.\n",
      "\n",
      "--- Sample of a Structured MITRE Document ---\n",
      "{\n",
      "  \"text\": \"MITRE ATT&CK Technique ID: T1055.011. Name: Extra Window Memory Injection. Tactic(s): Defense Evasion, Privilege Escalation. Description: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade process-based defenses as well as possibly elevate privileges. EWM injection is a method of executing arbitrary code in the address space of a separate live process. \\n\\nBefore creating a window, graphical Windows-based processes must prescribe to or register a windows class, which stipulate appearance and behavior (via windows procedures, which are functions that handle input/output of data).(Citation: Microsoft Window Classes) Registration of new windows classes can include a request for up to 40 bytes of EWM to be appended to the allocated memory of each instance of that class. This EWM is intended to store data specific to that window and has specific application programming interface (API) functions to set and get its value. (Citation: Microsoft GetWindowLong function) (Citation: Microsoft SetWindowLong function)\\n\\nAlthough small, the EWM is large enough to store a 32-bit pointer and is often used to point to a windows procedure. Malware may possibly utilize this memory location in part of an attack chain that includes writing code to shared sections of the process\\u2019s memory, placing a pointer to the code in EWM, then invoking execution by returning execution control to the address in the process\\u2019s EWM.\\n\\nExecution granted through EWM injection may allow access to both the target process's memory and possibly elevated privileges. Writing payloads to shared sections also avoids the use of highly monitored API calls such as <code>WriteProcessMemory</code> and <code>CreateRemoteThread</code>.(Citation: Elastic Process Injection July 2017) More sophisticated malware samples may also potentially bypass protection mechanisms such as data execution prevention (DEP) by triggering a combination of windows procedures and other system functions that will rewrite the malicious payload inside an executable portion of the target process.  (Citation: MalwareTech Power Loader Aug 2013) (Citation: WeLiveSecurity Gapz and Redyms Mar 2013)\\n\\nRunning code in the context of another process may allow access to the process's memory, system/network resources, and possibly elevated privileges. Execution via EWM injection may also evade detection from security products since the execution is masked under a legitimate process. \\n\\n**MITIGATION STRATEGIES:**\\n - Mitigation (M1040): Behavior Prevention on Endpoint refers to the use of technologies and strategies to detect and block potentially malicious activities by analyzing the behavior of processes, files, API calls, and other endpoint events. Rather than relying solely on known signatures, this approach leverages heuristics, machine learning, and real-time monitoring to identify anomalous patterns indicative of an attack. This mitigation can be implemented through the following measures:\\n\\nSuspicious Process Behavior:\\n\\n- Implementation: Use Endpoint Detection and Response (EDR) tools to monitor and block processes exhibiting unusual behavior, such as privilege escalation attempts.\\n- Use Case: An attacker uses a known vulnerability to spawn a privileged process from a user-level application. The endpoint tool detects the abnormal parent-child process relationship and blocks the action.\\n\\nUnauthorized File Access:\\n\\n- Implementation: Leverage Data Loss Prevention (DLP) or endpoint tools to block processes attempting to access sensitive files without proper authorization.\\n- Use Case: A process tries to read or modify a sensitive file located in a restricted directory, such as /etc/shadow on Linux or the SAM registry hive on Windows. The endpoint tool identifies this anomalous behavior and prevents it.\\n\\nAbnormal API Calls:\\n\\n- Implementation: Implement runtime analysis tools to monitor API calls and block those associated with malicious activities.\\n- Use Case: A process dynamically injects itself into another process to hijack its execution. The endpoint detects the abnormal use of APIs like `OpenProcess` and `WriteProcessMemory` and terminates the offending process.\\n\\nExploit Prevention:\\n\\n- Implementation: Use behavioral exploit prevention tools to detect and block exploits attempting to gain unauthorized access.\\n- Use Case: A buffer overflow exploit is launched against a vulnerable application. The endpoint detects the anomalous memory write operation and halts the process.\",\n",
      "  \"metadata\": {\n",
      "    \"id\": \"T1055.011\",\n",
      "    \"name\": \"Extra Window Memory Injection\",\n",
      "    \"source\": \"MITRE-ATTACK\",\n",
      "    \"type\": \"Technique-Mitigation\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# NOTE: Ensure this path is correct\n",
    "MITRE_JSON_PATH = 'enterprise-attack-17.1.json' \n",
    "\n",
    "def load_and_extract_mitre_data_raw(file_path):\n",
    "    \"\"\"\n",
    "    Loads the MITRE STIX JSON and extracts data using direct dictionary access \n",
    "    and Python filtering, bypassing the stix2.MemoryStore query model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading and extracting data using raw JSON processing ---\")\n",
    "    \n",
    "    # 1. Load the raw JSON file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if 'objects' not in data or not isinstance(data['objects'], list):\n",
    "        raise ValueError(\"MITRE STIX JSON does not contain a valid 'objects' list.\")\n",
    "\n",
    "    # Convert the list of objects to a dictionary for fast lookups by STIX ID\n",
    "    stix_objects = {obj['id']: obj for obj in data['objects']}\n",
    "    \n",
    "    mitre_documents = []\n",
    "    \n",
    "    # 2. Separate all Techniques and Mitigations\n",
    "    techniques = [obj for obj in stix_objects.values() if obj.get('type') == 'attack-pattern']\n",
    "    relationships = [obj for obj in stix_objects.values() if obj.get('type') == 'relationship' and obj.get('relationship_type') == 'mitigates']\n",
    "    mitigation_objects = [obj for obj in stix_objects.values() if obj.get('type') == 'course-of-action']\n",
    "    \n",
    "    print(f\"Found {len(techniques)} ATT&CK Techniques and {len(relationships)} Mitigation Relationships.\")\n",
    "\n",
    "    # 3. Process Techniques and link relevant mitigations\n",
    "    for tech in techniques:\n",
    "        tech_id = next((ref['external_id'] for ref in tech.get('external_references', []) if ref.get('source_name') == 'mitre-attack'), None)\n",
    "        if not tech_id:\n",
    "            continue # Skip if no MITRE ID found\n",
    "            \n",
    "        # Extract Tactic(s)\n",
    "        tactics_list = [\n",
    "            t['phase_name'].replace('-', ' ').title() \n",
    "            for t in tech.get('kill_chain_phases', []) \n",
    "            if t.get('kill_chain_name') == 'mitre-attack'\n",
    "        ]\n",
    "\n",
    "        core_text = (\n",
    "            f\"MITRE ATT&CK Technique ID: {tech_id}. \"\n",
    "            f\"Name: {tech.get('name', 'N/A')}. \"\n",
    "            f\"Tactic(s): {', '.join(tactics_list)}. \"\n",
    "            f\"Description: {tech.get('description', 'No description available.')}\"\n",
    "        )\n",
    "        \n",
    "        mitigation_text = []\n",
    "        \n",
    "        # Find relationships where the current technique is the target\n",
    "        relevant_rels = [rel for rel in relationships if rel.get('target_ref') == tech.get('id')]\n",
    "        \n",
    "        for rel in relevant_rels:\n",
    "            # Look up the actual mitigation object using the relationship's source_ref\n",
    "            mitigation_obj = stix_objects.get(rel.get('source_ref'))\n",
    "            \n",
    "            if mitigation_obj:\n",
    "                mitigation_id = next(\n",
    "                    (ref['external_id'] for ref in mitigation_obj.get('external_references', []) if ref.get('source_name') == 'mitre-attack'), \n",
    "                    'N/A'\n",
    "                )\n",
    "                mitigation_text.append(f\" - Mitigation ({mitigation_id}): {mitigation_obj.get('description', 'No details.')}\")\n",
    "\n",
    "        if mitigation_text:\n",
    "            core_text += \"\\n\\n**MITIGATION STRATEGIES:**\\n\" + \"\\n\".join(mitigation_text)\n",
    "\n",
    "        # 4. Create the final structured RAG document\n",
    "        mitre_documents.append({\n",
    "            'text': core_text,\n",
    "            'metadata': {\n",
    "                'id': tech_id,\n",
    "                'name': tech.get('name', 'N/A'),\n",
    "                'source': 'MITRE-ATTACK',\n",
    "                'type': 'Technique-Mitigation',\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    print(\"Raw JSON processing complete.\")\n",
    "    return mitre_documents\n",
    "\n",
    "# --- Execution ---\n",
    "try:\n",
    "    mitre_corpus = load_and_extract_mitre_data_raw(MITRE_JSON_PATH)\n",
    "\n",
    "    if mitre_corpus:\n",
    "        print(f\"\\nSuccessfully created RAG corpus with {len(mitre_corpus)} MITRE documents.\")\n",
    "        print(\"\\n--- Sample of a Structured MITRE Document ---\")\n",
    "        \n",
    "        # Find a sample document (e.g., one with known mitigations)\n",
    "        # We search for any document that has the mitigation header for a good sample\n",
    "        sample_doc = next(doc for doc in mitre_corpus if \"MITIGATION STRATEGIES\" in doc['text'])\n",
    "\n",
    "        print(json.dumps(sample_doc, indent=2))\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: MITRE JSON file not found at {MITRE_JSON_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unrecoverable error occurred during processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423315e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a. Processing CVE data from CSV...\n",
      "1b. Processing MITRE data from enterprise-attack-17.1.json (Simulated)...\n",
      "Total documents loaded for indexing: 5\n",
      "2. Splitting documents into manageable chunks...\n",
      "Initial documents: 5. Final chunks created: 5\n",
      "3. Initializing Embedding Model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kappa\\AppData\\Local\\Temp\\ipykernel_24644\\1750913183.py:111: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
      "c:\\Users\\kappa\\OneDrive\\sem5\\ML\\vir\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\kappa\\OneDrive\\sem5\\ML\\vir\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kappa\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3b. Indexing 5 chunks into Vector DB at ./chroma_db_v_rag...\n",
      "\n",
      "âœ… PHASE 1 COMPLETE: Knowledge Base Indexed Successfully.\n",
      "Vector Database stored locally at: ./chroma_db_v_rag\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from stix2 import MemoryStore\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- CORRECTED LangChain Imports ---\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_core.documents import Document # <-- FIX: Moved to langchain_core\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CVE_CSV_PATH = \"cve_raw_data.csv\"\n",
    "MITRE_JSON_PATH = \"enterprise-attack-17.1.json\"\n",
    "VECTOR_DB_PATH = \"./chroma_db_v_rag\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\" \n",
    "\n",
    "# --- 1. DATA UNIFICATION & FORMATTING ---\n",
    "\n",
    "def load_and_process_data(cve_path: str, mitre_path: str) -> List[Document]:\n",
    "    \"\"\"Loads, formats, and merges the CVE and MITRE data into a unified list of Document objects.\"\"\"\n",
    "    \n",
    "    # --- 1a. SIMULATED CVE DATA PROCESSING ---\n",
    "    print(\"1a. Processing CVE data from CSV...\")\n",
    "    \n",
    "    # --- SIMULATION START (Based on your image) ---\n",
    "    raw_cve_data = {\n",
    "        'outputs': [\n",
    "            \"CVE:CVE-2020-13909\\nDescription:The Ignition component before 2.0.5 for Laravel mishandles globals. Mitigation: Update to 2.0.5. published:2020-06-07T20:15:19.140\",\n",
    "            \"CVE:CVE-2021-3002\\nDescription:See Panel 4.8.0 allows reflected XSS via the email parameter. Mitigation: Patch to 4.8.1. published:2021-01-01T19:15:11.077\",\n",
    "            \"CVE:CVE-2024-55555\\nDescription:Critical zero-day RCE in Windows Print Spooler. Mitigation: Disable the Spooler service. published:2024-10-15T00:00:00.000\"\n",
    "        ]\n",
    "    }\n",
    "    cve_df = pd.DataFrame(raw_cve_data)\n",
    "    # --- SIMULATION END ---\n",
    "\n",
    "    cve_corpus = []\n",
    "    for index, row in cve_df.iterrows():\n",
    "        raw_output = row['outputs']\n",
    "        \n",
    "        try:\n",
    "            cve_id = raw_output.split('\\n')[0].replace('CVE:', '').strip()\n",
    "            description = raw_output.split('Description:')[1].split('published:')[0].strip()\n",
    "            \n",
    "            text_body = (\n",
    "                f\"VULNERABILITY ID: {cve_id}. \"\n",
    "                f\"Full Context: {description}\"\n",
    "            )\n",
    "            \n",
    "            cve_corpus.append(Document(\n",
    "                page_content=text_body,\n",
    "                metadata={\n",
    "                    'id': cve_id,\n",
    "                    'source': 'CVE-DB',\n",
    "                    'type': 'Vulnerability-Record',\n",
    "                }\n",
    "            ))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # --- 1b. SIMULATED MITRE DATA PROCESSING ---\n",
    "    print(f\"1b. Processing MITRE data from {mitre_path} (Simulated)...\")\n",
    "    \n",
    "    # --- SIMULATION START ---\n",
    "    # This represents the successful list of dicts from your MITRE JSON processor\n",
    "    mitre_corpus_dicts = [\n",
    "        {\n",
    "            \"text\": \"MITRE ATT&CK Technique ID: T1055.011. Name: Extra Window Memory Injection... MITIGATION STRATEGIES: - Mitigation (M1040): Behavior Prevention on Endpoint...\",\n",
    "            \"metadata\": {\"id\": \"T1055.011\", \"source\": \"MITRE-ATTACK\", \"type\": \"Technique-Mitigation\"}\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"MITRE ATT&CK Technique ID: T1566.001. Name: Spearphishing Attachment. Tactic(s): Initial Access. Description: Adversaries may send a spearphishing attachment...\",\n",
    "            \"metadata\": {\"id\": \"T1566.001\", \"source\": \"MITRE-ATTACK\", \"type\": \"Technique\"}\n",
    "        }\n",
    "    ]\n",
    "    mitre_corpus = [Document(page_content=d['text'], metadata=d['metadata']) for d in mitre_corpus_dicts]\n",
    "    # --- SIMULATION END ---\n",
    "\n",
    "\n",
    "    # --- 1c. Final Merge ---\n",
    "    final_corpus = cve_corpus + mitre_corpus\n",
    "    print(f\"Total documents loaded for indexing: {len(final_corpus)}\")\n",
    "    return final_corpus\n",
    "\n",
    "# --- 2. CHUNKING (TEXT SPLITTING) ---\n",
    "\n",
    "def split_documents(documents: List[Document]) -> List[Document]:\n",
    "    \"\"\"Splits large documents into smaller, context-rich chunks.\"\"\"\n",
    "    print(\"2. Splitting documents into manageable chunks...\")\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=900,         # Max size of each chunk\n",
    "        chunk_overlap=150,      # Overlap ensures context is maintained across split\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] \n",
    "    )\n",
    "    \n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Initial documents: {len(documents)}. Final chunks created: {len(chunked_documents)}\")\n",
    "    return chunked_documents\n",
    "\n",
    "# --- 3. EMBEDDING AND INDEXING ---\n",
    "\n",
    "def index_corpus(documents: List[Document], db_path: str, model_name: str):\n",
    "    \"\"\"Generates embeddings and indexes the chunks into ChromaDB.\"\"\"\n",
    "    print(f\"3. Initializing Embedding Model: {model_name}...\")\n",
    "    \n",
    "    # 3a. Initialize the embedding model\n",
    "    embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "    \n",
    "    print(f\"3b. Indexing {len(documents)} chunks into Vector DB at {db_path}...\")\n",
    "    \n",
    "    # 3c. Create the Chroma vector store index\n",
    "    Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_function,\n",
    "        persist_directory=db_path\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… PHASE 1 COMPLETE: Knowledge Base Indexed Successfully.\")\n",
    "    print(f\"Vector Database stored locally at: {db_path}\")\n",
    "\n",
    "# --- MAIN EXECUTION FLOW ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Step 1: Load and Unify\n",
    "        corpus = load_and_process_data(CVE_CSV_PATH, MITRE_JSON_PATH)\n",
    "        \n",
    "        # Step 2: Chunking\n",
    "        if corpus:\n",
    "            chunks = split_documents(corpus)\n",
    "            \n",
    "            # Step 3: Embedding and Indexing\n",
    "            index_corpus(chunks, VECTOR_DB_PATH, EMBEDDING_MODEL_NAME)\n",
    "        else:\n",
    "            print(\"ðŸ›‘ Cannot proceed: Corpus is empty after loading/processing.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- FATAL ERROR ---\")\n",
    "        print(f\"An error prevented indexing: {e}\")\n",
    "        print(\"Please ensure all dependencies are installed and accessible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
